{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing as proc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "data = pd.read_csv('training.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0  Chromosome   Position  Variant_Classification  \\\n0             0           1    2488139                       1   \n1             2           1  120612018                       4   \n2             4           4   57798317                       2   \n3             8           6  161807842                       1   \n4            17          20   31386449                       3   \n..          ...         ...        ...                     ...   \n148      140430          11  108178704                       1   \n149      141120          12   49426892                       1   \n150      141902          13   32929387                       0   \n151      144588          17   41228505                       0   \n152      148100          23   44929062                       1   \n\n     Reference_Allele  Tumor_Seq_Allele1  Tumor_Seq_Allele2  HGVSc  HGVSp  \\\n0                   2                  2                  0     56     88   \n1                   1                  3                  3     59     64   \n2                   0                  3                  3     50     83   \n3                   2                  3                  3      6     79   \n4                   3                  3                  1     24     95   \n..                ...                ...                ...    ...    ...   \n148                 1                  1                  3     81     24   \n149                 2                  2                  0      7     32   \n150                 3                  1                  1     96     99   \n151                 1                  1                  3     67      3   \n152                 1                  1                  0     33     81   \n\n     Exon_Number  ...  Codons  STRAND_VEP  EXON  IMPACT  GENE_PHENO  FILTER  \\\n0              4  ...      66         1.0    73       0         1.0       0   \n1              2  ...      34        -1.0    78       0         1.0       0   \n2             61  ...      52         1.0    57       0         1.0       0   \n3              5  ...      53        -1.0    14       0         1.0       0   \n4             29  ...      63         1.0    29       1         1.0       1   \n..           ...  ...     ...         ...   ...     ...         ...     ...   \n148           55  ...       4         1.0    55       0         1.0       0   \n149           56  ...       5        -1.0    56       0         1.0       0   \n150           25  ...      42         1.0    25       2         1.0       1   \n151           24  ...      28        -1.0    24       2         1.0       0   \n152           31  ...      53         1.0    31       0         1.0       0   \n\n     flanking_bps  vcf_qual  MUTATION_EFFECT  ONCOGENIC  \n0              26     31.76                3          2  \n1              22     45.74                3          2  \n2              31    186.03                3          2  \n3              37     29.79                3          2  \n4               8     16.16                3          2  \n..            ...       ...              ...        ...  \n148             2     31.40                3          2  \n149            40     50.09                3          2  \n150            29    217.61                6          5  \n151            14     41.37                6          5  \n152            33     50.00                3          2  \n\n[153 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Chromosome</th>\n      <th>Position</th>\n      <th>Variant_Classification</th>\n      <th>Reference_Allele</th>\n      <th>Tumor_Seq_Allele1</th>\n      <th>Tumor_Seq_Allele2</th>\n      <th>HGVSc</th>\n      <th>HGVSp</th>\n      <th>Exon_Number</th>\n      <th>...</th>\n      <th>Codons</th>\n      <th>STRAND_VEP</th>\n      <th>EXON</th>\n      <th>IMPACT</th>\n      <th>GENE_PHENO</th>\n      <th>FILTER</th>\n      <th>flanking_bps</th>\n      <th>vcf_qual</th>\n      <th>MUTATION_EFFECT</th>\n      <th>ONCOGENIC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2488139</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>56</td>\n      <td>88</td>\n      <td>4</td>\n      <td>...</td>\n      <td>66</td>\n      <td>1.0</td>\n      <td>73</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>26</td>\n      <td>31.76</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>120612018</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>59</td>\n      <td>64</td>\n      <td>2</td>\n      <td>...</td>\n      <td>34</td>\n      <td>-1.0</td>\n      <td>78</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>22</td>\n      <td>45.74</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>4</td>\n      <td>57798317</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>50</td>\n      <td>83</td>\n      <td>61</td>\n      <td>...</td>\n      <td>52</td>\n      <td>1.0</td>\n      <td>57</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>31</td>\n      <td>186.03</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8</td>\n      <td>6</td>\n      <td>161807842</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>6</td>\n      <td>79</td>\n      <td>5</td>\n      <td>...</td>\n      <td>53</td>\n      <td>-1.0</td>\n      <td>14</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>37</td>\n      <td>29.79</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>20</td>\n      <td>31386449</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>24</td>\n      <td>95</td>\n      <td>29</td>\n      <td>...</td>\n      <td>63</td>\n      <td>1.0</td>\n      <td>29</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>8</td>\n      <td>16.16</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>140430</td>\n      <td>11</td>\n      <td>108178704</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>81</td>\n      <td>24</td>\n      <td>55</td>\n      <td>...</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>55</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>31.40</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>141120</td>\n      <td>12</td>\n      <td>49426892</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>7</td>\n      <td>32</td>\n      <td>56</td>\n      <td>...</td>\n      <td>5</td>\n      <td>-1.0</td>\n      <td>56</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>50.09</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>141902</td>\n      <td>13</td>\n      <td>32929387</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>96</td>\n      <td>99</td>\n      <td>25</td>\n      <td>...</td>\n      <td>42</td>\n      <td>1.0</td>\n      <td>25</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>29</td>\n      <td>217.61</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>144588</td>\n      <td>17</td>\n      <td>41228505</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>67</td>\n      <td>3</td>\n      <td>24</td>\n      <td>...</td>\n      <td>28</td>\n      <td>-1.0</td>\n      <td>24</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>14</td>\n      <td>41.37</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>148100</td>\n      <td>23</td>\n      <td>44929062</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>33</td>\n      <td>81</td>\n      <td>31</td>\n      <td>...</td>\n      <td>53</td>\n      <td>1.0</td>\n      <td>31</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>33</td>\n      <td>50.00</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>153 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "X = data.loc[:, data.columns != 'IMPACT'].values\n",
    "y = data['IMPACT'].values\n",
    "scaler = proc.StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.58732524, -1.62617121, -1.21633967, ..., -0.45524558,\n        -0.4459799 , -0.36888344],\n       [-1.58727892, -1.62617121,  1.11358929, ..., -0.38406013,\n        -0.4459799 , -0.36888344],\n       [-1.5872326 , -1.10997993, -0.12537664, ...,  0.33028947,\n        -0.4459799 , -0.36888344],\n       ...,\n       [ 1.69923383,  0.4385939 , -0.61590269, ...,  0.49109324,\n         1.34967601,  1.5124221 ],\n       [ 1.76144364,  1.12684893, -0.45220712, ..., -0.40631195,\n         1.34967601,  1.5124221 ],\n       [ 1.84278426,  2.15923148, -0.37921566, ..., -0.36236842,\n        -0.4459799 , -0.36888344]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# fit the classifier to the data\n",
    "knn.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
    "y = np.array([1, 1, 2, 2])\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X, y)\n",
    "make_pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                ('svc', SVC(gamma='auto'))])\n",
    "print(clf.predict([[-0.8, -1]]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# learning vector quantitation\n",
    "import math\n",
    "\n",
    "class LVQ():\n",
    "\n",
    "    # Function here computes the winning vector\n",
    "    # by Euclidean distance\n",
    "    def winner( self, weights, sample ) :\n",
    "\n",
    "        D0 = 0\n",
    "        D1 = 0\n",
    "\n",
    "        for i  in range( len( sample ) ) :\n",
    "            D0 = D0 + math.pow( ( sample[i] - weights[0][i] ), 2 )\n",
    "            D1 = D1 + math.pow( ( sample[i] - weights[1][i] ), 2 )\n",
    "\n",
    "        if D0 > D1 :\n",
    "            return 0\n",
    "        else :\n",
    "            return 1\n",
    "\n",
    "    # Function here updates the winning vector\n",
    "    def update( self, weights, sample, J, alpha, actual ) :\n",
    "          if actual -- J:\n",
    "            for i in range(len(weights)) :\n",
    "                weights[J][i] = weights[J][i] + alpha * ( sample[i] - weights[J][i] )\n",
    "          else:\n",
    "            for i in range(len(weights)) :\n",
    "                weights[J][i] = weights[J][i] - alpha * ( sample[i] - weights[J][i] )\n",
    "\n",
    "    # Training Samples ( m, n ) with their class vector\n",
    "    X =  [[ 0, 0, 1, 1 ],  [ 1, 0, 0, 0 ],\n",
    "          [ 0, 0, 0, 1 ], [ 0, 1, 1, 0 ],\n",
    "          [ 1, 1, 0, 0 ], [ 1, 1, 1, 0 ],]\n",
    "\n",
    "    Y = [ 0, 1, 0, 1, 1, 1 ]\n",
    "    m, n = len( X ), len( X[0] )\n",
    "\n",
    "    # weight initialization ( n, c )\n",
    "    weights = []\n",
    "    weights.append( X.pop( 0 ) )\n",
    "    weights.append( X.pop( 0 ) )\n",
    "\n",
    "    # Samples used in weight initialization will\n",
    "    # not use in training\n",
    "    m = m - 2\n",
    "    Y.pop(0)\n",
    "    Y.pop(0)\n",
    "\n",
    "    # training\n",
    "    ob = LVQ()\n",
    "    epochs = 3\n",
    "    alpha = 0.1\n",
    "\n",
    "    for i in range( epochs ) :\n",
    "        for j in range( m ) :\n",
    "\n",
    "            # Sample selection\n",
    "            T = X[j]\n",
    "\n",
    "            # Compute winner\n",
    "            J = ob.winner( weights, T )\n",
    "\n",
    "            # Update weights\n",
    "            ob.update( weights, T, J, alpha , Y[j])\n",
    "\n",
    "    # classify new input sample\n",
    "    T = [ 0, 0, 1, 0 ]\n",
    "    J = ob.winner( weights, T )\n",
    "    print( \"Sample T belongs to class : \", J )\n",
    "    print( \"Trained weights : \", weights )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# self organizing map\n",
    "import numpy as np\n",
    "from minisom import MiniSom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define the dataset\n",
    "data = np.array([[0.2, 0.4, 0.6],\n",
    "                 [0.4, 0.6, 0.8],\n",
    "                 [0.1, 0.3, 0.5],\n",
    "                 [0.3, 0.5, 0.7]])\n",
    "\n",
    "# create the SOM\n",
    "som_shape = (2, 2)\n",
    "input_len = data.shape[1]\n",
    "som = MiniSom(*som_shape, input_len)\n",
    "\n",
    "# initialize the weights randomly\n",
    "som.random_weights_init(data)\n",
    "\n",
    "# train the SOM for 100 iterations\n",
    "som.train_random(data, 100)\n",
    "\n",
    "# plot the resulting map\n",
    "plt.pcolor(som.distance_map().T, cmap='bone_r')\n",
    "plt.colorbar()\n",
    "\n",
    "# mark the training data on the map\n",
    "markers = ['o', 's', 'D', 'v']\n",
    "colors = ['r', 'g', 'b', 'y']\n",
    "for i, x in enumerate(data):\n",
    "    w = som.winner(x)\n",
    "    plt.plot(w[0] + 0.5, w[1] + 0.5, markers[i], markeredgecolor=colors[i], markerfacecolor='None', markersize=12, markeredgewidth=2)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "0-dimensional array given. Array must be at least two-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mLinAlgError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 18\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# predict the target variable for new input points\u001B[39;00m\n\u001B[0;32m     17\u001B[0m X_test \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39mnp\u001B[38;5;241m.\u001B[39mpi, \u001B[38;5;241m100\u001B[39m)\n\u001B[1;32m---> 18\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m [lwr_predict(x, X, y, tau\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m X_test]\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# plot the results\u001B[39;00m\n\u001B[0;32m     21\u001B[0m plt\u001B[38;5;241m.\u001B[39mscatter(X, y, color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mblue\u001B[39m\u001B[38;5;124m'\u001B[39m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[2], line 18\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# predict the target variable for new input points\u001B[39;00m\n\u001B[0;32m     17\u001B[0m X_test \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39mnp\u001B[38;5;241m.\u001B[39mpi, \u001B[38;5;241m100\u001B[39m)\n\u001B[1;32m---> 18\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m [\u001B[43mlwr_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtau\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m X_test]\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# plot the results\u001B[39;00m\n\u001B[0;32m     21\u001B[0m plt\u001B[38;5;241m.\u001B[39mscatter(X, y, color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mblue\u001B[39m\u001B[38;5;124m'\u001B[39m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[2], line 13\u001B[0m, in \u001B[0;36mlwr_predict\u001B[1;34m(x, X, y, tau)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlwr_predict\u001B[39m(x, X, y, tau):\n\u001B[0;32m     12\u001B[0m     w \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39m((X \u001B[38;5;241m-\u001B[39m x) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m tau \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m))\n\u001B[1;32m---> 13\u001B[0m     theta \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinalg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m@\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mw\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m@\u001B[39m (X\u001B[38;5;241m.\u001B[39mT \u001B[38;5;241m@\u001B[39m (w \u001B[38;5;241m*\u001B[39m y))\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x \u001B[38;5;241m*\u001B[39m theta\n",
      "File \u001B[1;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36minv\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32m~\\Desktop\\python_envs\\proj3_env\\lib\\site-packages\\numpy\\linalg\\linalg.py:532\u001B[0m, in \u001B[0;36minv\u001B[1;34m(a)\u001B[0m\n\u001B[0;32m    471\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    472\u001B[0m \u001B[38;5;124;03mCompute the (multiplicative) inverse of a matrix.\u001B[39;00m\n\u001B[0;32m    473\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    529\u001B[0m \n\u001B[0;32m    530\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    531\u001B[0m a, wrap \u001B[38;5;241m=\u001B[39m _makearray(a)\n\u001B[1;32m--> 532\u001B[0m \u001B[43m_assert_stacked_2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    533\u001B[0m _assert_stacked_square(a)\n\u001B[0;32m    534\u001B[0m t, result_t \u001B[38;5;241m=\u001B[39m _commonType(a)\n",
      "File \u001B[1;32m~\\Desktop\\python_envs\\proj3_env\\lib\\site-packages\\numpy\\linalg\\linalg.py:183\u001B[0m, in \u001B[0;36m_assert_stacked_2d\u001B[1;34m(*arrays)\u001B[0m\n\u001B[0;32m    181\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m arrays:\n\u001B[0;32m    182\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m a\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m--> 183\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LinAlgError(\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m-dimensional array given. Array must be \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    184\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mat least two-dimensional\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m a\u001B[38;5;241m.\u001B[39mndim)\n",
      "\u001B[1;31mLinAlgError\u001B[0m: 0-dimensional array given. Array must be at least two-dimensional"
     ]
    }
   ],
   "source": [
    "# Locally weighted regression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generate some random data\n",
    "np.random.seed(0)\n",
    "X = np.linspace(0, 2*np.pi, 100)\n",
    "y = np.sin(X) + np.random.normal(0, 0.1, len(X))\n",
    "\n",
    "# define the LWR function\n",
    "def lwr_predict(x, X, y, tau):\n",
    "    w = np.exp(-((X - x) ** 2) / (2 * tau ** 2))\n",
    "    theta = np.linalg.inv(X.T @ (w * X)) @ (X.T @ (w * y))\n",
    "    return x * theta\n",
    "\n",
    "# predict the target variable for new input points\n",
    "X_test = np.linspace(0, 2*np.pi, 100)\n",
    "y_pred = [lwr_predict(x, X, y, tau=0.1) for x in X_test]\n",
    "\n",
    "# plot the results\n",
    "plt.scatter(X, y, color='blue', alpha=0.5, label='data')\n",
    "plt.plot(X_test, y_pred, color='red', label='LWR prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6086956521739131\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# create a Gaussian Naive Bayes classifier\n",
    "clf = GaussianNB()\n",
    "\n",
    "# train the classifier on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6086956521739131\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# create a Gaussian Naive Bayes classifier\n",
    "clf = GaussianNB()\n",
    "\n",
    "# train the classifier on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2608695652173913\n"
     ]
    }
   ],
   "source": [
    "# multinomial naive bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load the 20 newsgroups dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# convert the text into a bag of words representation\n",
    "vectorizer = CountVectorizer()\n",
    "# X = vectorizer.fit_transform(X)\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.abs(X), y, test_size=0.3, random_state=0)\n",
    "\n",
    "# create a Multinomial Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# train the classifier on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.32608695652173914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoli\\AppData\\Local\\Temp\\ipykernel_7468\\758007664.py:50: RuntimeWarning: overflow encountered in exp\n",
      "  probs = np.exp(log_probs)\n"
     ]
    }
   ],
   "source": [
    "# Averaged One-dependence Estimators\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "class AODE:\n",
    "    def __init__(self, alpha=1):\n",
    "        self.alpha = alpha\n",
    "        self.class_prior_ = None\n",
    "        self.feature_log_prob_ = None\n",
    "        self.ode_probs_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.class_prior_ = np.zeros(np.max(y) + 1)\n",
    "        self.feature_log_prob_ = np.zeros((np.max(y) + 1, n_features))\n",
    "        self.ode_probs_ = np.zeros((np.max(y) + 1, n_features))\n",
    "\n",
    "        # calculate class priors and feature probabilities\n",
    "        for c in range(np.max(y) + 1):\n",
    "            self.class_prior_[c] = (y == c).sum() / n_samples\n",
    "            self.feature_log_prob_[c] = np.log((X[y == c] + self.alpha).sum(axis=0) / ((y == c).sum() + 2*self.alpha))\n",
    "\n",
    "        # calculate ODE probabilities\n",
    "        for c in range(np.max(y) + 1):\n",
    "            for i in range(n_features):\n",
    "                for j in range(i+1, n_features):\n",
    "                    p_ij = np.zeros((2, 2))\n",
    "                    p_ij[0, 0] = np.sum((X[:, i] == 0) & (X[:, j] == 0) & (y == c))\n",
    "                    p_ij[0, 1] = np.sum((X[:, i] == 0) & (X[:, j] == 1) & (y == c))\n",
    "                    p_ij[1, 0] = np.sum((X[:, i] == 1) & (X[:, j] == 0) & (y == c))\n",
    "                    p_ij[1, 1] = np.sum((X[:, i] == 1) & (X[:, j] == 1) & (y == c))\n",
    "                    self.ode_probs_[c, i] += np.log((p_ij[1, 1] + self.alpha) / (p_ij[1, 0] + p_ij[1, 1] + 2*self.alpha))\n",
    "                    self.ode_probs_[c, j] += np.log((p_ij[1, 1] + self.alpha) / (p_ij[0, 1] + p_ij[1, 1] + 2*self.alpha))\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_classes = len(self.class_prior_)\n",
    "        log_probs = np.zeros((n_samples, n_classes))\n",
    "\n",
    "        # calculate class conditional probabilities\n",
    "        for c in range(n_classes):\n",
    "            log_probs[:, c] += np.log(self.class_prior_[c])\n",
    "            log_probs[:, c] += np.sum(self.feature_log_prob_[c, :][None, :] * X, axis=1)\n",
    "            log_probs[:, c] += np.sum(self.ode_probs_[c, :][None, :] * X[:, None, :] * (1 - X[:, :, None]), axis=(1, 2))\n",
    "\n",
    "        # calculate posterior probabilities\n",
    "        probs = np.exp(log_probs)\n",
    "        probs = np.sum(probs, axis=1)[:, None]\n",
    "\n",
    "        # return class predictions\n",
    "        return np.argmax(probs, axis=1)\n",
    "\n",
    "model = AODE()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "+------+----------+\n",
      "| E    |   phi(E) |\n",
      "+======+==========+\n",
      "| E(0) |   0.9030 |\n",
      "+------+----------+\n",
      "| E(1) |   0.0970 |\n",
      "+------+----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoli\\Desktop\\python_envs\\proj3_env\\lib\\site-packages\\pgmpy\\models\\BayesianModel.py:8: FutureWarning: BayesianModel has been renamed to BayesianNetwork. Please use BayesianNetwork class, BayesianModel will be removed in future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# bayesian belief network\n",
    "\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.inference import VariableElimination\n",
    "import numpy as np\n",
    "\n",
    "# create Bayesian network model\n",
    "model = BayesianModel([('A', 'B'), ('C', 'B'), ('C', 'D'), ('B', 'E')])\n",
    "\n",
    "# create conditional probability distributions\n",
    "cpd_a = TabularCPD('A', 2, [[0.6], [0.4]])\n",
    "cpd_c = TabularCPD('C', 2, [[0.5], [0.5]])\n",
    "cpd_b = TabularCPD('B', 2, [[0.9, 0.7, 0.8, 0.1], [0.1, 0.3, 0.2, 0.9]], evidence=['A', 'C'], evidence_card=[2, 2])\n",
    "cpd_d = TabularCPD('D', 2, [[0.9, 0.3], [0.1, 0.7]], evidence=['C'], evidence_card=[2])\n",
    "cpd_e = TabularCPD('E', 2, [[0.99, 0.7], [0.01, 0.3]], evidence=['B'], evidence_card=[2])\n",
    "\n",
    "# add conditional probability distributions to model\n",
    "model.add_cpds(cpd_a, cpd_c, cpd_b, cpd_d, cpd_e)\n",
    "\n",
    "# check if model is valid\n",
    "print(model.check_model())\n",
    "\n",
    "# create variable elimination inference object\n",
    "infer = VariableElimination(model)\n",
    "\n",
    "# infer probabilities for a given observation\n",
    "obs = {'A': 0, 'C': 1}\n",
    "prob = infer.query(['E'], evidence=obs)\n",
    "print(prob)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoli\\Desktop\\python_envs\\proj3_env\\lib\\site-packages\\pgmpy\\models\\BayesianModel.py:8: FutureWarning: BayesianModel has been renamed to BayesianNetwork. Please use BayesianNetwork class, BayesianModel will be removed in future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# bayesian network\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "\n",
    "# create the Bayesian network model\n",
    "model = BayesianModel([('D', 'G'), ('I', 'G'), ('G', 'L'), ('G', 'S')])\n",
    "\n",
    "# create the conditional probability distributions\n",
    "cpd_d = TabularCPD('D', 2, [[0.6], [0.4]])\n",
    "cpd_i = TabularCPD('I', 2, [[0.7], [0.3]])\n",
    "cpd_g = TabularCPD('G', 3, [[0.3, 0.05, 0.9, 0.5], [0.4, 0.25, 0.08, 0.3], [0.3, 0.7, 0.02, 0.2]],\n",
    "                   evidence=['D', 'I'], evidence_card=[2, 2])\n",
    "cpd_l = TabularCPD('L', 2, [[0.1, 0.4, 0.99], [0.9, 0.6, 0.01]], evidence=['G'], evidence_card=[3])\n",
    "cpd_s = TabularCPD('S', 2, [[0.5, 0.9, 0.7], [0.5, 0.1, 0.3]], evidence=['G'], evidence_card=[3])\n",
    "\n",
    "# add the conditional probability distributions to the model\n",
    "model.add_cpds(cpd_d, cpd_i, cpd_g, cpd_l, cpd_s)\n",
    "\n",
    "# check if the model is valid\n",
    "print(model.check_model())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
